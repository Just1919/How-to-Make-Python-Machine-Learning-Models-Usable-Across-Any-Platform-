{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3F1ESKM8s7sH/dlr9L73b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Just1919/How-to-Make-Python-Machine-Learning-Models-Usable-Across-Any-Platform-/blob/main/Consuming_a_Python_Model_from_a_Python_Client_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Deploying Machine Learning Models**\n",
        "\n",
        "Medium link Article 1:"
      ],
      "metadata": {
        "id": "p2fRukQItCC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Article :  Consuming a Python Model from a Python Client\n"
      ],
      "metadata": {
        "id": "5KH6zN1J1F-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At first glance, using a Python model from a Python client seems straightforward—simply call predict (or predict_proba for a classifier) on the trained model. However, you wouldn’t want to retrain the model every time you need to use it. Instead, the goal is to train it once and allow client applications to reload it in its pre-trained state whenever needed.\n",
        "To achieve this, Python developers commonly rely on the pickle module.\n",
        "For illustration, the following code trains a model using the well-known Iris dataset. Instead of immediately using the model for predictions, it saves the trained model to a .pkl file—this process, known as \"pickling,\" is done using pickle.dump on the final line:"
      ],
      "metadata": {
        "id": "Uag3korjExmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "B1wI4gl11FiK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sC-PRUFSse40"
      },
      "outputs": [],
      "source": [
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the class distribution in the original dataset\n",
        "print(\"Class distribution in the original dataset:\")\n",
        "print(Counter(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFMggrNm3Jhb",
        "outputId": "d6ea8853-3c20-4316-8e5c-220f66dd254c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in the original dataset:\n",
            "Counter({0: 50, 1: 50, 2: 50})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and test sets, using stratify to ensure class distribution is similar in both sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Initialize and train a Random Forest classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model to a .pkl file\n",
        "with open('iris_model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WePG_V_H2Oq4",
        "outputId": "89335fb4-b889-495f-ff71-4fdabd789385"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The stratify=y parameter in train_test_split ensures that the class distribution in the training and test sets is the same as in the original dataset. This is particularly important in classification problems to make sure that each class is represented proportionally in both sets. Without stratification, you could end up with imbalanced splits, especially when the dataset has uneven class distribution.\n",
        "In the case of the Iris dataset, the target classes (species of flowers) are fairly balanced, but using stratify=y guarantees that the proportions of each class in the training and test sets will match the original distribution. This improves the model’s performance and ensures more reliable results during evaluation."
      ],
      "metadata": {
        "id": "81s0E5V_E_XB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Faire des prédictions sur l'ensemble de test\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Évaluer la performance du modèle\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKztlfC25t_3",
        "outputId": "49d2a784-e711-4372-f68d-4ecafe517f90"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 88.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the model, a Python client utilizes pickle.load to load the serialized model from the .pkl file, effectively restoring it to its trained state. The client then calls predict_proba to estimate the probabilities that the iris\n",
        "belongs to a specific species."
      ],
      "metadata": {
        "id": "iPCj1BaVFOwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model from the .pkl file\n",
        "with open('iris_model.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n"
      ],
      "metadata": {
        "id": "ef6C9brn2wAW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the client can use the model to make a prediction without retraining it. And once the model is loaded, it can persist for the lifetime of the client and be called upon for predictions whenever needed."
      ],
      "metadata": {
        "id": "nMbpUMlyGQo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input data (one sample)\n",
        "sample_data = np.array([[5.1, 3.5, 1.4, 0.2]])\n",
        "\n",
        "# Use the model to predict the class index\n",
        "predicted_class_index = model.predict(sample_data)\n",
        "\n",
        "# Map the class index to the class name\n",
        "class_names = ['setosa', 'versicolor', 'virginica']\n",
        "predicted_class_name = class_names[predicted_class_index[0]]\n",
        "\n",
        "# Use the model to predict probabilities\n",
        "probabilities = model.predict_proba(sample_data)\n",
        "print(\"Probabilities:\")\n",
        "print(probabilities)\n",
        "\n",
        "# Display the predicted class name\n",
        "print(f\"Predicted class: {predicted_class_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0VT3_CuGZfT",
        "outputId": "6f344254-a522-48c1-c8a9-95db88fb4ddc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities:\n",
            "[[1. 0. 0.]]\n",
            "Predicted class: setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Versioning Pickle Files\n",
        "\n",
        "In general, a model saved (pickled) using one version of Scikit-learn may not be compatible with another version when attempting to unpickle it. This can lead to warning messages, or in some cases, the model may not load at all. To avoid this issue, it's essential to save and load models using the same version of Scikit-learn. From an engineering standpoint, this requires careful planning, as any updates to the Scikit-learn version in your applications will also necessitate updating the serialized models stored in your repository.\n"
      ],
      "metadata": {
        "id": "HLdzhTcIGauG"
      }
    }
  ]
}